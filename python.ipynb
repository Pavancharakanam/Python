{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python startup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse(value):\n",
    "    output = value[::-1]\n",
    "    return output\n",
    "\n",
    "string = reverse(\"hello\")\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv file and write it to another csv or txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(r'C:\\Users\\pavan\\OneDrive\\Desktop\\DataEng\\Python\\california_housing_test.csv', mode = 'r') as file:\n",
    "    data = csv.reader(file)\n",
    "    \n",
    "    with open('output.csv', mode = 'w') as output_file:\n",
    "        output_writer=csv.writer(output_file,delimiter='-')\n",
    "        for rec in data:\n",
    "            output_writer.writerow(rec)\n",
    "\n",
    "   \n",
    "file.close()\n",
    "output_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas and its funtions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('output.csv')\n",
    "\n",
    "# print(\"Raw data\\n\",df.to_string())\n",
    "\n",
    "# new_df = df.dropna()\n",
    "# print(\"altered data:\\n\",new_df.to_string())\n",
    "\n",
    "# new_df = df.fillna('filled')\n",
    "# print(\"new data\\n\", new_df)\n",
    "\n",
    "#df['Age'].fillna(100, inplace=True)\n",
    "# print(\"tranformed data\\n\",df)\n",
    "\n",
    "avg_age = df['Age'].add_suffix('|')\n",
    "print(avg_age.sort_values(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nth(data,n):\n",
    "    \n",
    "    df = pd.DataFrame(data,columns=['Id', 'Salary'])\n",
    "    print(\"data:\\n\",df)\n",
    "    print(\"length of data:\",len(df))\n",
    "    \n",
    "    sorted_data = df['Salary'].sort_values(ascending=False)\n",
    "    print(sorted_data)\n",
    "    \n",
    "    if len(sorted_data)<n:\n",
    "        print(\"There is no {} highest salary\".format(n))\n",
    "    else:\n",
    "        print('{} highest salary is:'.format(n),sorted_data.iloc[n])\n",
    "\n",
    "\n",
    "data = [[12, 900], [2, 200], [3, 300],[9,300]]\n",
    "result = nth(data,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Department': ['Sales', 'Sales', 'HR', 'HR', 'Engineering', 'Engineering'],\n",
    " 'Salary': [60000, 80000, 75000, 65000, 72000, 90000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.groupby('Department')['Salary'].max().reset_index()\n",
    "\n",
    "df = df[df['Salary']> 82000]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dt = [1,2,3,4,5]\n",
    "\n",
    "arr = np.zeros(5)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "    \n",
    "cursor = None \n",
    "connection = None \n",
    "country=[]\n",
    "\n",
    "try:\n",
    "    connection = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"root\", host='192.168.5.56', port=5432)\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    #sql section \n",
    "    sel_script = ''' select * from country; '''\n",
    "    cursor.execute(sel_script)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    #sql to Data Frame\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values(by=0,ascending=True)\n",
    "    limit = df.__len__()    \n",
    "    \n",
    "    #output section \n",
    "    with open(\"country.txt\",mode = 'w') as of:\n",
    "        of_writer=csv.writer(of)\n",
    "        for i in range(0,limit):\n",
    "            x=df.iloc[i]\n",
    "            x= x.str.upper()\n",
    "            of_writer.writerow(x)\n",
    "            \n",
    "    print(\"{} file created\".format(\"country.txt\"))\n",
    "    \n",
    "    #New table definition\n",
    "    table_name = 'country_new'\n",
    "    column1 = 'id'\n",
    "    column2 = 'name'\n",
    "    \n",
    "    try:\n",
    "        sql_create = '''create table if not exists \n",
    "                            {} (\n",
    "                            {} INT,\n",
    "                            {} VARCHAR(20)\n",
    "                                );\n",
    "                        truncate table {};'''.format(table_name,column1,column2,table_name)\n",
    "                                \n",
    "        cursor.execute(sql_create)\n",
    "        connection.commit() \n",
    "\n",
    "        print(\"Table created\")\n",
    "    except Exception as error:\n",
    "            print(\"table created failed:\",error)\n",
    "        \n",
    "\n",
    "    try:\n",
    "        id=0  \n",
    "        for rec in range (0,limit-1):\n",
    "            id+=1\n",
    "            val=df[0][rec]\n",
    "            val=val.upper()\n",
    "            sql_insert = ''' insert into {} ({},{})\n",
    "                                    values (%s,%s);\n",
    "                            '''.format(table_name,column1,column2)\n",
    "            \n",
    "            cursor.execute(sql_insert,(id,val))\n",
    "            connection.commit()\n",
    "        \n",
    "        print(\"Records inserted:\",id)    \n",
    "    except Exception as error:\n",
    "        print(\"table insertion failed:\",error)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "finally:\n",
    "    if cursor and connection is not None:\n",
    "        of.close()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"Program execution complete\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python and snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import csv\n",
    "\n",
    "\n",
    "con = snowflake.connector.connect(\n",
    "    account='RGXQNUE-AW70262',\n",
    "    user='SAI',\n",
    "    password='Plmnko@5',\n",
    "    warehouse='COMPUTE_WH',\n",
    "    database='DBT_SNOWFLAKE',\n",
    "    schema='DBT_SNOWFLAKE_SCHEMA'\n",
    "    )\n",
    "\n",
    "cur = con.cursor()\n",
    "\n",
    "sql_script = \"select * from chargeback\"\n",
    "\n",
    "cur.execute(sql_script)\n",
    "rows = cur.fetchall()\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python and PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case -  CB533260077601\n",
      "Dates: ['11/04/23', '11/04/23', '11/05/23']\n",
      "card: ['3775']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#from pdfminer.high_level import extract_pages, extract_text\n",
    "from pypdf import PdfReader\n",
    "import pandas as pd\n",
    "\n",
    "lst=[]\n",
    "dates = []\n",
    "cards=[]\n",
    "folio = PdfReader(r'C:\\Users\\pavan\\OneDrive\\Desktop\\DataEng\\Python\\Docs\\Crystal Reports - rptFolio1.rpt.pdf')\n",
    "\n",
    "cover = PdfReader(r'C:\\Users\\pavan\\OneDrive\\Desktop\\DataEng\\Python\\Docs\\Cover Letter.pdf')\n",
    "\n",
    "# print('Folio letter total pages: ',len(folio.pages))\n",
    "# print('Cover letter total pages: ',len(cover.pages))\n",
    "\n",
    "cover_lines = cover.pages[0].extract_text()\n",
    "folio_lines = folio.pages[0].extract_text()\n",
    "\n",
    "cover_lines=cover_lines.splitlines()\n",
    "\n",
    "#regex\n",
    "pattern_card = r'(\\d{4})'\n",
    "pattern_date = r'(\\d{2}/\\d{2}/\\d{2})'\n",
    "    \n",
    "for case in cover_lines:\n",
    "    \n",
    "    #get case number\n",
    "    if case!=' ' and not case.rfind('CASE'):\n",
    "        if case != ' ':\n",
    "            index=case.find(':')\n",
    "            case_number = case[index::].strip(':').strip(' ')\n",
    "        else:\n",
    "            print(\"Case number missing in Cover Letter\")\n",
    "    \n",
    "    \n",
    "    #fetch dates \n",
    "\n",
    "    match = re.search(pattern_date,case)\n",
    "    \n",
    "    if match:\n",
    "        lst = case.split(' ')\n",
    "        for i in lst:\n",
    "            if re.search(pattern_date,i):\n",
    "                dates.append(i.strip(',').strip(' '))\n",
    "\n",
    "\n",
    "    #fetch card\n",
    "    lst = case.split(' ')\n",
    "    for i in lst:\n",
    "        match = re.search(pattern_card,i)\n",
    "        if match:\n",
    "            i= i.strip(',').strip(' ').strip(').')\n",
    "            if len(i) == 4:\n",
    "                cards.append(i)\n",
    "            \n",
    "                \n",
    "        \n",
    "print(\"case - \",case_number)\n",
    "print(\"Dates:\", dates)\n",
    "print(\"card:\", cards )\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
